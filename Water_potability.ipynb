{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chansek03/water_potability/blob/main/Water_potability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kNxCiwmCwCZQ",
        "outputId": "f468d306-a657-459d-fe23-aacea2deb021"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
              "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
              "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5208271-152f-465a-8ad7-c62638399888\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5208271-152f-465a-8ad7-c62638399888')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5208271-152f-465a-8ad7-c62638399888 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5208271-152f-465a-8ad7-c62638399888');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-506751a5-1660-4ba1-88ad-874078952a7d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-506751a5-1660-4ba1-88ad-874078952a7d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-506751a5-1660-4ba1-88ad-874078952a7d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv(\"/content/water_potability.csv\")\n",
        "\n",
        "# View the first 5 rows\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdmuReIEPMDc",
        "outputId": "44d44ba1-8c4a-4b7a-ad65-e420cfd2fd85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ph                 491\n",
              "Hardness             0\n",
              "Solids               0\n",
              "Chloramines          0\n",
              "Sulfate            781\n",
              "Conductivity         0\n",
              "Organic_carbon       0\n",
              "Trihalomethanes    162\n",
              "Turbidity            0\n",
              "Potability           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGNuW1swQANX",
        "outputId": "ac540ce4-31f9-46ae-a72e-98ebf77012ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ph                     7.080795\n",
              "Hardness             196.369496\n",
              "Solids             22014.092526\n",
              "Chloramines            7.122277\n",
              "Sulfate              333.775777\n",
              "Conductivity         426.205111\n",
              "Organic_carbon        14.284970\n",
              "Trihalomethanes       66.396293\n",
              "Turbidity              3.966786\n",
              "Potability             0.390110\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#mean of columns\n",
        "data.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Pd7tOwR4QF8r",
        "outputId": "1294f160-7dfd-44d2-df84-8fa74db81413"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
              "3271  4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
              "3272  7.808856  193.553212  17329.802160     8.061362  333.775777   \n",
              "3273  9.419510  175.762646  33155.578218     7.350233  333.775777   \n",
              "3274  5.126763  230.603758  11983.869376     6.303357  333.775777   \n",
              "3275  7.874671  195.102299  17404.177061     7.509306  333.775777   \n",
              "\n",
              "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
              "3272    392.449580       19.903225        66.396293   2.798243           1  \n",
              "3273    432.044783       11.039070        69.845400   3.298875           1  \n",
              "3274    402.883113       11.168946        77.488213   4.708658           1  \n",
              "3275    327.459760       16.140368        78.698446   2.309149           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02f5dd79-24bb-44b7-93f6-bc21edb8f92b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3271</th>\n",
              "      <td>4.668102</td>\n",
              "      <td>193.681735</td>\n",
              "      <td>47580.991603</td>\n",
              "      <td>7.166639</td>\n",
              "      <td>359.948574</td>\n",
              "      <td>526.424171</td>\n",
              "      <td>13.894419</td>\n",
              "      <td>66.687695</td>\n",
              "      <td>4.435821</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3272</th>\n",
              "      <td>7.808856</td>\n",
              "      <td>193.553212</td>\n",
              "      <td>17329.802160</td>\n",
              "      <td>8.061362</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>392.449580</td>\n",
              "      <td>19.903225</td>\n",
              "      <td>66.396293</td>\n",
              "      <td>2.798243</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3273</th>\n",
              "      <td>9.419510</td>\n",
              "      <td>175.762646</td>\n",
              "      <td>33155.578218</td>\n",
              "      <td>7.350233</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>432.044783</td>\n",
              "      <td>11.039070</td>\n",
              "      <td>69.845400</td>\n",
              "      <td>3.298875</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3274</th>\n",
              "      <td>5.126763</td>\n",
              "      <td>230.603758</td>\n",
              "      <td>11983.869376</td>\n",
              "      <td>6.303357</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>402.883113</td>\n",
              "      <td>11.168946</td>\n",
              "      <td>77.488213</td>\n",
              "      <td>4.708658</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3275</th>\n",
              "      <td>7.874671</td>\n",
              "      <td>195.102299</td>\n",
              "      <td>17404.177061</td>\n",
              "      <td>7.509306</td>\n",
              "      <td>333.775777</td>\n",
              "      <td>327.459760</td>\n",
              "      <td>16.140368</td>\n",
              "      <td>78.698446</td>\n",
              "      <td>2.309149</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02f5dd79-24bb-44b7-93f6-bc21edb8f92b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02f5dd79-24bb-44b7-93f6-bc21edb8f92b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02f5dd79-24bb-44b7-93f6-bc21edb8f92b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4f9c5e3-6c44-4f53-8d73-81006c5bab85\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4f9c5e3-6c44-4f53-8d73-81006c5bab85')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4f9c5e3-6c44-4f53-8d73-81006c5bab85 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data['ph'].fillna(data['ph'].mean(),inplace=True)\n",
        "data['Sulfate'].fillna(data['Sulfate'].mean(),inplace=True)\n",
        "data['Trihalomethanes'].fillna(data['Trihalomethanes'].mean(),inplace=True)\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z_634O_SVZD",
        "outputId": "396a8db9-3016-4969-e6be-d764c991c810"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ph                 0\n",
              "Hardness           0\n",
              "Solids             0\n",
              "Chloramines        0\n",
              "Sulfate            0\n",
              "Conductivity       0\n",
              "Organic_carbon     0\n",
              "Trihalomethanes    0\n",
              "Turbidity          0\n",
              "Potability         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwMNs4KVafns",
        "outputId": "aae73ec3-57d2-47c0-fc12-ac2bda9ee63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32760\n",
            "(3276, 10)\n"
          ]
        }
      ],
      "source": [
        "print(data.size)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs1YGjhfk99o",
        "outputId": "3530b5df-4df1-42ab-8fcd-bb360fe46a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset (Before SMOTE):\n",
            "0    1998\n",
            "1    1278\n",
            "Name: Potability, dtype: int64\n",
            "\n",
            "Resampled Dataset (After SMOTE):\n",
            "0    1998\n",
            "1    1998\n",
            "Name: Potability, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Count the number of zeros (non-potable) and ones (potable) in the original dataset\n",
        "count_before_smote = y.value_counts()\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Count the number of zeros and ones in the resampled dataset\n",
        "count_after_smote = pd.Series(y_resampled).value_counts()\n",
        "\n",
        "print(\"Original Dataset (Before SMOTE):\")\n",
        "print(count_before_smote)\n",
        "\n",
        "print(\"\\nResampled Dataset (After SMOTE):\")\n",
        "print(count_after_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwU0008GBsjv",
        "outputId": "d71a043a-d44e-456a-aed3-9bcb7417c729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6265243902439024\n",
            "Confusion Matrix:\n",
            "[[411   1]\n",
            " [244   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77       412\n",
            "           1       0.00      0.00      0.00       244\n",
            "\n",
            "    accuracy                           0.63       656\n",
            "   macro avg       0.31      0.50      0.39       656\n",
            "weighted avg       0.39      0.63      0.48       656\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm_classifier = SVC(kernel= 'rbf', gamma= 'scale', C= 10)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4AaL9FBtS5k",
        "outputId": "bacc8739-cb32-45db-b76c-0fa206c54a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Best model's accuracy on the test set: 0.6814024390243902\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# Define a grid of hyperparameters to search over\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data with cross-validation\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best model's accuracy on the test set:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIEPZdqOnQxL",
        "outputId": "957c6e8f-0fba-4a85-fc79-c272fc1ee53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'n_neighbors': 11, 'p': 2, 'weights': 'uniform'}\n",
            "Best model's accuracy on the test set: 0.5655487804878049\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# Define a grid of hyperparameters to search over\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2],  # 1 for Manhattan distance, 2 for Euclidean distance\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=knn_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data with cross-validation\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_knn_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best model's accuracy on the test set:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3UqJo6gqejm",
        "outputId": "e51fe9de-cdb8-4c61-aa47-4c2de98db41f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best model's accuracy on the test set: 0.6280487804878049\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression()\n",
        "\n",
        "# Define a grid of hyperparameters to search over\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear'],\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=lr_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data with cross-validation\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_lr_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_lr_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best model's accuracy on the test set:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "2aQXroZpr1x7",
        "outputId": "64258965-b777-402c-8ab2-e8254dae4294"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "classifiers = {\n",
        "    'SVM': SVC(kernel= 'rbf', gamma= 'scale', C= 10),\n",
        "    'Random Forest': RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform'),\n",
        "    'Logistic Regression': LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[name] = accuracy\n",
        "\n",
        "# Create a bar plot to compare the results\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.bar(results.keys(), results.values(), color=['blue', 'green', 'orange', 'red'])\n",
        "plt.xlabel('Algorithms')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Algorithm Performance')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x6lfYpQN9lV",
        "outputId": "1e82fb08-4d87-4129-abdd-ac54347555c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.6432926829268293\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create individual classifiers\n",
        "svm_classifier = SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True)\n",
        "rf_classifier = RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform')\n",
        "lr_classifier = LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')\n",
        "\n",
        "\n",
        "# Create a VotingClassifier for ensemble\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('SVM', svm_classifier),\n",
        "        ('Random Forest', rf_classifier),\n",
        "        ('KNN', knn_classifier),\n",
        "        ('Logistic Regression', lr_classifier)\n",
        "    ],\n",
        "    voting='soft'  # Use soft voting for probability-based prediction\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ensemble Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO_ByXMmVCdE",
        "outputId": "f374cc0e-ac9b-4ce1-9ee1-3294a2c14088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-Learner (Random Forest) Accuracy: 0.6814024390243902\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create individual classifiers\n",
        "svm_classifier = SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform')\n",
        "lr_classifier = LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')\n",
        "\n",
        "# Create a VotingClassifier for the first-level ensemble\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('SVM', svm_classifier),\n",
        "        ('KNN', knn_classifier),\n",
        "        ('Logistic Regression', lr_classifier)\n",
        "    ],\n",
        "    voting='soft'  # Use soft voting for probability-based prediction\n",
        ")\n",
        "\n",
        "# Create the Random Forest meta-learner\n",
        "meta_learner = RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42)\n",
        "\n",
        "# Train the ensemble classifiers on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "meta_learner.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set using base classifiers\n",
        "base_predictions = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Make predictions on the test set using the Random Forest meta-learner\n",
        "meta_predictions = meta_learner.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score of the ensemble (meta-learner) predictions\n",
        "accuracy = accuracy_score(y_test, meta_predictions)\n",
        "print(f\"Meta-Learner (Random Forest) Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Serq2gZ2Lw",
        "outputId": "c4349391-1ce7-40fe-ecc5-f6bfe36a8c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'alpha': 0.1}\n",
            "Best model's accuracy on the test set: 0.5167682926829268\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Multinomial Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Define a grid of hyperparameters to search over\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0]  # Example values for the alpha parameter\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data with cross-validation\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_nb_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_nb_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best model's accuracy on the test set:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3m2MxVnOwvh",
        "outputId": "2ab398a8-97c8-48c9-8d2b-6598f2392129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'priors': [0.6, 0.4], 'reg_param': 0.1}\n",
            "Best model's accuracy on the test set: 0.6890243902439024\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Quadratic Discriminant Analysis classifier\n",
        "qda_classifier = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "# Define a grid of hyperparameters to search over\n",
        "param_grid = {\n",
        "    'reg_param': [0.0, 0.1, 0.2, 0.3],  # Regularization parameter (shrinkage)\n",
        "    'priors': [None, [0.5, 0.5], [0.6, 0.4], [0.7, 0.3]]  # Class priors\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=qda_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data with cross-validation\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_qda_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_qda_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best model's accuracy on the test set:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXBO-oiQPhX1",
        "outputId": "a3a81549-2225-446c-8e40-8d131a48a101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 0.1. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy: 0.6158536585365854\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a range of hyperparameters to search over (e.g., for RBF kernel length scale and constant)\n",
        "param_grid = {\n",
        "    'kernel': [C(1.0, (1e-1, 1e3)) * RBF(1.0, (1e-2, 1e2))],\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "# Perform a grid search over the specified hyperparameter range\n",
        "for kernel in param_grid['kernel']:\n",
        "    gp_classifier = GaussianProcessClassifier(kernel=kernel)\n",
        "    gp_classifier.fit(X_train, y_train)\n",
        "    y_pred = gp_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = gp_classifier\n",
        "\n",
        "print(\"Best accuracy:\", best_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umNWmQoAV6tF",
        "outputId": "0b403192-2904-4ea8-9b70-e69ac73b17a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
            "Best model's accuracy on the test set: 0.6067073170731707\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Define a grid of hyperparameters to search over\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data with cross-validation\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_dt_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_dt_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best model's accuracy on the test set:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ujp5Q8l1P_Ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a7772b-7ed3-478a-e5c9-43fe60054ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.6448170731707317\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create individual classifiers\n",
        "svm_classifier = SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True)\n",
        "rf_classifier = RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform')\n",
        "lr_classifier = LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')\n",
        "gp_classifier = GaussianProcessClassifier()\n",
        "qda_classifier = QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1)\n",
        "nb_classifier = MultinomialNB(alpha= 0.1)\n",
        "dt_classifier = DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 2, min_samples_split= 10)\n",
        "\n",
        "# Create a VotingClassifier for the ensemble\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('SVM', svm_classifier),\n",
        "        ('Random Forest', rf_classifier),\n",
        "        ('KNN', knn_classifier),\n",
        "        ('Logistic Regression', lr_classifier),\n",
        "        ('Gaussian Process', gp_classifier),\n",
        "        ('Quadratic Discriminant', qda_classifier),\n",
        "        ('Naive Bayes', nb_classifier),\n",
        "        ('Decision Tree', dt_classifier),\n",
        "    ],\n",
        "    voting='soft'  # Use hard voting for majority voting\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score of the ensemble\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ensemble Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNOmd8kKayAP",
        "outputId": "4fdf5a97-b555-4149-850b-5ba856d6496a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble with Random Forest as Meta-Learner Accuracy: 0.6920731707317073\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create base classifiers\n",
        "base_classifiers = [\n",
        "    ('SVM', SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True)),\n",
        "    ('KNN', KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform')),\n",
        "    ('Logistic Regression',LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')),\n",
        "    ('Gaussian Process', GaussianProcessClassifier()),\n",
        "    ('Quadratic Discriminant',QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1) ),\n",
        "    ('Naive Bayes', MultinomialNB(alpha= 0.1)),\n",
        "    ('Decision Tree', DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 2, min_samples_split= 10)),\n",
        "    ('Random forest', RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42))\n",
        "]\n",
        "\n",
        "# Create a VotingClassifier for the base classifiers\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=base_classifiers,\n",
        "    voting='soft'  # Use soft voting for probability-based prediction\n",
        ")\n",
        "\n",
        "# Create the Random Forest classifier as the meta-learner\n",
        "meta_learner = RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42)\n",
        "\n",
        "# Combine the base classifiers and the meta-learner in a VotingClassifier\n",
        "final_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('Ensemble', ensemble_classifier),\n",
        "        ('Random Forest', meta_learner)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "final_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ensemble with Random Forest as Meta-Learner Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create base classifiers\n",
        "base_classifiers = [\n",
        "    ('SVM', SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True)),\n",
        "    ('KNN', KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform')),\n",
        "    ('Logistic Regression',LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')),\n",
        "    ('Gaussian Process', GaussianProcessClassifier()),\n",
        "    ('Quadratic Discriminant',QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1) ),\n",
        "    ('Naive Bayes', MultinomialNB(alpha= 0.1)),\n",
        "    ('Decision Tree', DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 2, min_samples_split= 10)),\n",
        "    ('Random forest', RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42))\n",
        "]\n",
        "\n",
        "# Create a VotingClassifier for the base classifiers\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=base_classifiers,\n",
        "    voting='soft'  # Use soft voting for probability-based prediction\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get the initial ensemble accuracy\n",
        "initial_accuracy = accuracy_score(y_test, ensemble_classifier.predict(X_test))\n",
        "\n",
        "# Create a list to store the names of the worst models\n",
        "worst_models = []\n",
        "\n",
        "# Initialize variables to keep track of the worst models and their corresponding accuracies\n",
        "worst_model_names = []\n",
        "worst_model_accuracies = []\n",
        "\n",
        "# Calculate the accuracy of each base classifier\n",
        "for name, classifier in base_classifiers:\n",
        "    classifier.fit(X_train, y_train)\n",
        "    accuracy = accuracy_score(y_test, classifier.predict(X_test))\n",
        "    worst_model_names.append(name)\n",
        "    worst_model_accuracies.append(accuracy)\n",
        "\n",
        "# Sort the models by accuracy and find the worst 4 models\n",
        "\n",
        "sorted_models = sorted(zip(worst_model_names, worst_model_accuracies), key=lambda x: x[1])\n",
        "worst_models = [model[0] for model in sorted_models[:5]]\n",
        "\n",
        "# Remove the worst models from the ensemble\n",
        "pruned_base_classifiers = [(name, classifier) for name, classifier in base_classifiers if name not in worst_models]\n",
        "\n",
        "\n",
        "# Create a new VotingClassifier without the worst models\n",
        "pruned_ensemble_classifier = VotingClassifier(\n",
        "    estimators=pruned_base_classifiers,\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# Train the pruned ensemble on the training data\n",
        "pruned_ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get the improved accuracy of the pruned ensemble\n",
        "improved_accuracy = accuracy_score(y_test, pruned_ensemble_classifier.predict(X_test))\n",
        "\n",
        "print(f\"Initial Ensemble Accuracy: {initial_accuracy}\")\n",
        "print(f\"Worst Models Removed: {worst_models}\")\n",
        "print(f\"Improved Ensemble Accuracy: {improved_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imx_Fna9wuAf",
        "outputId": "db265b4f-6ce0-43c5-c2e5-ff9b203d0e02"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Ensemble Accuracy: 0.6448170731707317\n",
            "Worst Models Removed: ['Naive Bayes', 'KNN', 'Decision Tree', 'Gaussian Process', 'SVM']\n",
            "Improved Ensemble Accuracy: 0.6920731707317073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import sys\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a dictionary of model names and corresponding model instances\n",
        "models = {\n",
        "    'SVM': SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform'),\n",
        "    'Logistic Regression':LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear'),\n",
        "    'Gaussian Process': GaussianProcessClassifier(),\n",
        "    'Quadratic Discriminant':QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1),\n",
        "    'Naive Bayes': MultinomialNB(alpha= 0.1),\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 2, min_samples_split= 10),\n",
        "    'Random forest': RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42)\n",
        "\n",
        "}\n",
        "\n",
        "# Initialize dictionaries to store accuracy, time, and space complexity information\n",
        "accuracy_ranking = {}\n",
        "time_complexity_ranking = {}\n",
        "space_complexity_ranking = {}\n",
        "\n",
        "# Iterate through the models and evaluate them\n",
        "for model_name, model in models.items():\n",
        "    # Evaluate accuracy\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    # Evaluate space complexity using sys.getsizeof\n",
        "    memory_usage = sys.getsizeof(model)\n",
        "\n",
        "    accuracy_ranking[model_name] = accuracy\n",
        "    time_complexity_ranking[model_name] = execution_time\n",
        "    space_complexity_ranking[model_name] = memory_usage\n",
        "\n",
        "# Rank models based on accuracy (higher is better)\n",
        "accuracy_ranking = {k: v for k, v in sorted(accuracy_ranking.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "# Rank models based on time complexity (lower is better)\n",
        "time_complexity_ranking = {k: v for k, v in sorted(time_complexity_ranking.items(), key=lambda item: item[1])}\n",
        "\n",
        "# Rank models based on space complexity (lower is better)\n",
        "space_complexity_ranking = {k: v for k, v in sorted(space_complexity_ranking.items(), key=lambda item: item[1])}\n",
        "\n",
        "# Print the rankings\n",
        "print(\"Ranking based on Accuracy:\")\n",
        "for idx, (model_name, accuracy) in enumerate(accuracy_ranking.items(), 1):\n",
        "    print(f\"{idx}. {model_name}: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nRanking based on Time Complexity:\")\n",
        "for idx, (model_name, time_complexity) in enumerate(time_complexity_ranking.items(), 1):\n",
        "    print(f\"{idx}. {model_name}: {time_complexity:.6f} seconds\")\n",
        "\n",
        "print(\"\\nRanking based on Space Complexity:\")\n",
        "for idx, (model_name, space_complexity) in enumerate(space_complexity_ranking.items(), 1):\n",
        "    print(f\"{idx}. {model_name}: {space_complexity} bytes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fUS_5p7dIE1",
        "outputId": "d3bc2c73-5ede-4505-ca46-07873ce61f6e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking based on Accuracy:\n",
            "1. Quadratic Discriminant: 0.6890\n",
            "2. Random forest: 0.6814\n",
            "3. Logistic Regression: 0.6280\n",
            "4. SVM: 0.6265\n",
            "5. Gaussian Process: 0.6159\n",
            "6. Decision Tree: 0.6098\n",
            "7. KNN: 0.5655\n",
            "8. Naive Bayes: 0.5168\n",
            "\n",
            "Ranking based on Time Complexity:\n",
            "1. Naive Bayes: 0.006575 seconds\n",
            "2. Quadratic Discriminant: 0.008027 seconds\n",
            "3. Logistic Regression: 0.014878 seconds\n",
            "4. Decision Tree: 0.037761 seconds\n",
            "5. KNN: 0.038547 seconds\n",
            "6. Random forest: 1.038873 seconds\n",
            "7. SVM: 4.722041 seconds\n",
            "8. Gaussian Process: 5.929552 seconds\n",
            "\n",
            "Ranking based on Space Complexity:\n",
            "1. SVM: 48 bytes\n",
            "2. KNN: 48 bytes\n",
            "3. Logistic Regression: 48 bytes\n",
            "4. Gaussian Process: 48 bytes\n",
            "5. Quadratic Discriminant: 48 bytes\n",
            "6. Naive Bayes: 48 bytes\n",
            "7. Decision Tree: 48 bytes\n",
            "8. Random forest: 48 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create base classifiers\n",
        "base_classifiers = [\n",
        "    ('SVM', SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True)),\n",
        "    ('KNN', KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform')),\n",
        "    ('Logistic Regression',LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')),\n",
        "    ('Gaussian Process', GaussianProcessClassifier()),\n",
        "    ('Quadratic Discriminant',QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1) ),\n",
        "    ('Naive Bayes', MultinomialNB(alpha= 0.1)),\n",
        "    ('Decision Tree', DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 2, min_samples_split= 10)),\n",
        "    ('Random forest', RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42))\n",
        "]\n",
        "\n",
        "# Create a VotingClassifier for the base classifiers\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=base_classifiers,\n",
        "    voting='soft'  # Use soft voting for probability-based prediction\n",
        ")\n",
        "\n",
        "# Initialize dictionaries to store accuracy, time, and space complexity information\n",
        "accuracy_ranking = {}\n",
        "time_complexity_ranking = {}\n",
        "space_complexity_ranking = {}\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "start_time = time.time()\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "# Evaluate accuracy\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "initial_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Evaluate space complexity using sys.getsizeof\n",
        "memory_usage = sys.getsizeof(ensemble_classifier)\n",
        "\n",
        "accuracy_ranking['Ensemble'] = initial_accuracy\n",
        "time_complexity_ranking['Ensemble'] = execution_time\n",
        "space_complexity_ranking['Ensemble'] = memory_usage\n",
        "\n",
        "# Rank models based on accuracy (higher is better)\n",
        "accuracy_ranking = {k: v for k, v in sorted(accuracy_ranking.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "# Rank models based on time complexity (lower is better)\n",
        "time_complexity_ranking = {k: v for k, v in sorted(time_complexity_ranking.items(), key=lambda item: item[1])}\n",
        "\n",
        "# Rank models based on space complexity (lower is better)\n",
        "space_complexity_ranking = {k: v for k, v in sorted(space_complexity_ranking.items(), key=lambda item: item[1])}\n",
        "\n",
        "# Identify the 5 models with the least accuracies and remove them\n",
        "# You can customize the criteria for model removal\n",
        "num_models_to_remove = 5\n",
        "worst_models = []\n",
        "\n",
        "# Evaluate and remove the worst models\n",
        "for model_name, model in base_classifiers:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    worst_models.append((model_name, accuracy))\n",
        "\n",
        "worst_models.sort(key=lambda x: x[1])\n",
        "worst_models = worst_models[:num_models_to_remove]\n",
        "\n",
        "# Remove the worst models from the ensemble\n",
        "for model_name, _ in worst_models:\n",
        "    for idx, (base_model_name, _) in enumerate(ensemble_classifier.estimators):\n",
        "        if base_model_name == model_name:\n",
        "            del ensemble_classifier.estimators[idx]\n",
        "            break\n",
        "\n",
        "# Train the pruned ensemble on the training data\n",
        "start_time = time.time()\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "# Evaluate accuracy after pruning\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "pruned_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Evaluate space complexity after pruning\n",
        "pruned_memory_usage = sys.getsizeof(ensemble_classifier)\n",
        "\n",
        "# Print the rankings and removed model names\n",
        "print(\"Ranking based on Accuracy:\")\n",
        "for idx, (model_name, accuracy) in enumerate(accuracy_ranking.items(), 1):\n",
        "    print(f\"{idx}. {model_name}: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nRanking based on Time Complexity:\")\n",
        "for idx, (model_name, time_complexity) in enumerate(time_complexity_ranking.items(), 1):\n",
        "    print(f\"{idx}. {model_name}: {time_complexity:.6f} seconds\")\n",
        "\n",
        "print(\"\\nRanking based on Space Complexity:\")\n",
        "for idx, (model_name, space_complexity) in enumerate(space_complexity_ranking.items(), 1):\n",
        "    print(f\"{idx}. {model_name}: {space_complexity} bytes\")\n",
        "\n",
        "print(\"\\nRemoved Model Names:\")\n",
        "for idx, (model_name, _) in enumerate(worst_models, 1):\n",
        "    print(f\"{idx}. {model_name}\")\n",
        "\n",
        "print(f\"\\nAccuracy after Pruning: {pruned_accuracy:.4f}\")\n",
        "print(f\"Time Complexity after Pruning: {execution_time:.6f} seconds\")\n",
        "print(f\"Space Complexity after Pruning: {pruned_memory_usage} bytes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ic_JpZEk5Ky",
        "outputId": "a6664267-30ce-454f-9fad-48bb75e67d94"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking based on Accuracy:\n",
            "1. Ensemble: 0.6463\n",
            "\n",
            "Ranking based on Time Complexity:\n",
            "1. Ensemble: 11.714863 seconds\n",
            "\n",
            "Ranking based on Space Complexity:\n",
            "1. Ensemble: 48 bytes\n",
            "\n",
            "Removed Model Names:\n",
            "1. Naive Bayes\n",
            "2. KNN\n",
            "3. Decision Tree\n",
            "4. Gaussian Process\n",
            "5. SVM\n",
            "\n",
            "Accuracy after Pruning: 0.6921\n",
            "Time Complexity after Pruning: 1.130996 seconds\n",
            "Space Complexity after Pruning: 48 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d332122-3eaa-41b8-e621-e3a425de6e16",
        "id": "WcHIZVmBDT3R"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble with Random Forest as Meta-Learner Accuracy: 0.6920731707317073\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create base classifiers\n",
        "base_classifiers = [\n",
        "\n",
        "    ('Logistic Regression',LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')),\n",
        "\n",
        "    ('Quadratic Discriminant',QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1) )\n",
        "\n",
        "]\n",
        "\n",
        "# Create a VotingClassifier for the base classifiers\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=base_classifiers,\n",
        "    voting='soft'  # Use soft voting for probability-based prediction\n",
        ")\n",
        "\n",
        "# Create the Random Forest classifier as the meta-learner\n",
        "meta_learner = RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42)\n",
        "\n",
        "# Combine the base classifiers and the meta-learner in a VotingClassifier\n",
        "final_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('Ensemble', ensemble_classifier),\n",
        "        ('Random Forest', meta_learner)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "final_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ensemble with Random Forest as Meta-Learner Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1ac738-c7c4-4639-9a63-14d145e6cc1a",
        "id": "NWQqybloF1-w"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.6814024390243902\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create individual classifiers\n",
        "\n",
        "lr_classifier = LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')\n",
        "\n",
        "qda_classifier = QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1)\n",
        "\n",
        "\n",
        "\n",
        "# Create a VotingClassifier for the ensemble\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "\n",
        "\n",
        "        ('Logistic Regression', lr_classifier),\n",
        "        ('Quadratic Discriminant', qda_classifier),\n",
        "\n",
        "\n",
        "    ],\n",
        "    voting='soft'  # Use hard voting for majority voting\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score of the ensemble\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ensemble Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create base classifiers\n",
        "base_classifiers = [\n",
        "    ('SVM', SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True)),\n",
        "    ('KNN', KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform')),\n",
        "    ('Logistic Regression',LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')),\n",
        "    ('Gaussian Process', GaussianProcessClassifier()),\n",
        "    ('Quadratic Discriminant',QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1) ),\n",
        "    ('Naive Bayes', MultinomialNB(alpha= 0.1)),\n",
        "    ('Decision Tree', DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 2, min_samples_split= 10)),\n",
        "    ('Random forest', RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42))\n",
        "]\n",
        "\n",
        "# Fit the base classifiers on the training data and calculate their individual accuracies\n",
        "model_accuracies = {}\n",
        "for name, classifier in base_classifiers:\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    model_accuracies[name] = accuracy\n",
        "\n",
        "# Calculate the initial ensemble accuracy\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=base_classifiers,\n",
        "    voting='soft'\n",
        ")\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "y_pred_ensemble = ensemble_classifier.predict(X_test)\n",
        "initial_ensemble_accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
        "\n",
        "# Calculate the mean accuracy of all models\n",
        "mean_accuracy = np.mean(list(model_accuracies.values()))\n",
        "\n",
        "# Identify and remove the worst-performing models\n",
        "removed_models = []\n",
        "for name, accuracy in model_accuracies.items():\n",
        "    if accuracy < mean_accuracy:\n",
        "        removed_models.append(name)\n",
        "\n",
        "# Create a new ensemble without the removed models\n",
        "pruned_base_classifiers = [(name, classifier) for name, classifier in base_classifiers if name not in removed_models]\n",
        "pruned_ensemble_classifier = VotingClassifier(\n",
        "    estimators=pruned_base_classifiers,\n",
        "    voting='soft'\n",
        ")\n",
        "pruned_ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Calculate the final improved ensemble accuracy\n",
        "y_pred_pruned_ensemble = pruned_ensemble_classifier.predict(X_test)\n",
        "final_ensemble_accuracy = accuracy_score(y_test, y_pred_pruned_ensemble)\n",
        "\n",
        "print(f\"Initial Ensemble Accuracy: {initial_ensemble_accuracy}\")\n",
        "print(f\"Removed Models: {removed_models}\")\n",
        "print(f\"Final Improved Ensemble Accuracy: {final_ensemble_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZsR4druLAHH",
        "outputId": "5303067d-d8c7-46eb-fc68-6baf4c0c1780"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Ensemble Accuracy: 0.6448170731707317\n",
            "Removed Models: ['KNN', 'Gaussian Process', 'Naive Bayes', 'Decision Tree']\n",
            "Final Improved Ensemble Accuracy: 0.6844512195121951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = data.drop('Potability', axis=1)\n",
        "y = data['Potability']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create base classifiers\n",
        "base_classifiers = [\n",
        "    ('SVM', SVC(kernel= 'rbf', gamma= 'scale', C= 10, probability=True)),\n",
        "    ('KNN', KNeighborsClassifier(n_neighbors= 11, p= 2, weights= 'uniform')),\n",
        "    ('Logistic Regression',LogisticRegression(C= 1, penalty= 'l1', solver= 'liblinear')),\n",
        "    ('Gaussian Process', GaussianProcessClassifier()),\n",
        "    ('Quadratic Discriminant',QuadraticDiscriminantAnalysis(priors= [0.6, 0.4], reg_param= 0.1) ),\n",
        "    ('Naive Bayes', MultinomialNB(alpha= 0.1)),\n",
        "    ('Decision Tree', DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 2, min_samples_split= 10)),\n",
        "    ('Random forest', RandomForestClassifier(max_depth= 20, min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100, random_state=42))\n",
        "]\n",
        "\n",
        "# Create a VotingClassifier for the base classifiers\n",
        "ensemble_classifier = VotingClassifier(\n",
        "    estimators=base_classifiers,\n",
        "    voting='soft'  # Use soft voting for probability-based prediction\n",
        ")\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Measure the time taken by each model to make predictions\n",
        "times = []\n",
        "for name, classifier in base_classifiers:\n",
        "    start_time = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    times.append(elapsed_time)\n",
        "\n",
        "# Evaluate the initial ensemble accuracy\n",
        "initial_accuracy = accuracy_score(y_test, ensemble_classifier.predict(X_test))\n",
        "\n",
        "# Calculate the mean time complexity\n",
        "mean_time_complexity = sum(times) / len(times)\n",
        "# Calculate the mean accuracy of all models\n",
        "mean_accuracy = np.mean(list(model_accuracies.values()))\n",
        "# Initialize lists for new classifiers and removed models\n",
        "new_base_classifiers = []\n",
        "removed_models = []\n",
        "\n",
        "# Check models for removal\n",
        "for name, classifier in base_classifiers:\n",
        "    model_accuracy = accuracy_score(y_test, classifier.predict(X_test))\n",
        "    model_time_complexity = times[base_classifiers.index((name, classifier))]\n",
        "\n",
        "    if model_accuracy >= mean_accuracy and model_time_complexity <= mean_time_complexity:\n",
        "        new_base_classifiers.append((name, classifier))\n",
        "    else:\n",
        "        removed_models.append(name)\n",
        "\n",
        "# Create a new ensemble without the worst-performing models\n",
        "pruned_ensemble_classifier = VotingClassifier(\n",
        "    estimators=new_base_classifiers,\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# Train the pruned ensemble on the training data\n",
        "pruned_ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set with the pruned ensemble\n",
        "y_pred = pruned_ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the final improved accuracy\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the initial ensemble accuracy, removed models, and final improved accuracy\n",
        "print(f\"Initial Ensemble Accuracy: {initial_accuracy}\")\n",
        "print(f\"Removed Models: {removed_models}\")\n",
        "print(f\"Final Improved Accuracy: {final_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLEIggWB0AYl",
        "outputId": "f7bd00cd-c3bb-4968-9001-4f329c1b6328"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Ensemble Accuracy: 0.6463414634146342\n",
            "Removed Models: ['SVM', 'KNN', 'Gaussian Process', 'Naive Bayes', 'Decision Tree']\n",
            "Final Improved Accuracy: 0.6920731707317073\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCpFhKfwG64gqYp1dNMPZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}